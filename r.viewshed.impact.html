<h2>DESCRIPTION</h2>

<em>r.viewshed.impact</em> computes weighted (optional) visual impact
of each feature in a given exposure source vector map
using parametrised (optional) cumulative viewshed analysis.

<h2>NOTES</h2>

<h3>The algorithm</h3>
The processing workflow of the module consists of four steps that are
repeated iteratively for each feature of the input
exposure source vector map within the current computational region:
<ol>
<li>Random sampling of exposure source with vector points,</li>
<li>Calculating parametrised (optional) cumulative viewshed
  from random points using
  <a href="r.viewshed.exposurehtml">r.viewshed.exposure</a> module,</li>
<li>Optional multiplication of the (parametrised) cumulative  viewshed
  by weights raster,</li>
<li>Summarising the pixel values of the resulting visual impact
  raster and storing the value in the attribute
  table of the input exposure source map. </li>
</ol>

<div align="center" style="margin: 10px">
<a href="r_viewshed_impact_workflow.png">
<img src="r_viewshed_impact_workflow.png" width="485" height="637" alt="r.viewshed.impact workflow" border="0">
</a><br>
<i>Processing workflow</i>
</div>

<h4>1. Random sampling</h4>
The processed feature is randomly sampled by vector points
in defined sampling density (0-100%; option <b>sample_density</b>).
In general, lower sampling densities lead to lower
accuracy, higher uncertainty of the result and lower processing time,
while higher sampling densities lead to higher accuracy, lower uncertainty of
the result and longer processing time.

<h4>2. Calculating (parametrised) cumulative viewshed</h4>
The vector sampling points are then used as input into
<a href="r.viewshed.exposure.html">r.viewshed.exposure</a> module
to calculate (parametrised) cumulative viewshed from of the
processed feature, using the input digital surface
model (option <b>dsm</b>).
The height of the processed feature is considered
to be 0m above the input digital surface model.

<p>The following options are inherited from
<a href="r.viewshed.exposure.html">r.viewshed.exposure</a> module
and are thoroughly described in the documentation:
<b>observer_elevation</b>, <b>function</b>,
<b>b1_distance</b>, <b>refraction_coeff</b> and flags
<b>c</b> and <b>r</b>.

<p> The range of visual exposure can be specified either
  as constant (option <b>range_max</b>) or variable
  based on attribute value for the processed feature
  (option <b>range_col</b>).

<h4>3. (Optional) multiplication by weights raster</h4>
If the option <b>weight</b> is specified, the (parametrised)
cumulative viewshed is multiplied by a weight raster map.
This allows to account for variable visual
impact at different areas or to exclude specific areas from the
visual impact computation.

<h4>4. Summarising the visual impact value </h4>
The visual impact of the processed feature is expressed as a
sum of pixel values of the (weighted) (parametrised) cumulative
viewshed. The resulting value is stored in an
attribute table column of the input exposure source map
(option <b>column</b>). In addion, the resulting visual impact maps
created in step 3. can optionally be kept (flag <b>k</b>).

<h3>Memory and parallel processing</h3>
Option <b>memory</b> specifies the amount of memory allocated for
viewshed computation with
<a href="r.viewshed.exposure.html">r.viewshed.exposure</a>.

Option <b>cores_e</b> specifies the number of cores used in
parallel processing of
<a href="r.viewshed.exposure.html">r.viewshed.exposure</a>.

Option <b>cores_i</b> specifies the number of cores used in
parallel processing of the iteration over exposure source map
features.

A general advice is to use smaller number in <b>cores_e</b> and larger number
in <b>cores_i</b> in processing a dataset with many small polygons/lines/points
and larger number in <b>cores_e</b> in processing a dataset with larger
polygons.

<h2>EXAMPLES</h2>
Computation of visibility of geodetic points from urban areas in South-West Wake county,
North Carolina. Input data are a terrain model, a vector map of geodetic points
(exposure source) and a raster map of urban areas (weights) from NC dataset.
Viewshed parametrisation function is set to Distance decay, exposure range
is set to 500m.

<div class="code"><pre>
# set computation region to terrain model
g.region raster=elevation@PERMANENT

# copy vector maps of geodetic points to the current mapset
g.copy vector=geodetic_swwake_pts@PERMANENT,geodetic_swwake_pts_local

# calculate visibility of geodetic points from urban areas
# keep the resulting visual impact maps
r.viewshed.impact -k
  exposure=geodetic_swwake_pts_local
  column=visibility_urban
  dsm=elevation@PERMANENT
  weight=urban@PERMANENT
  observer_elevation=1.5
  range=500
  function=Distance_decay
  sample_density=100
  seed=1
  prefix=visual_impact_
  cores_e=1
  cores_i=4

</pre></div>

<div align="center" style="margin: 10px">
<a href="r_viewshed_impact_example_overview.png">
<img src="r_viewshed_impact_example_overview.png"
width="595" height="782"
alt="Example of r.viewshed.impact - visibility value" border="0">
</a><br>
<i>Example of r.viewshed.impact - visibility value</i>
</div>

<div align="center" style="margin: 10px">
<a href="r_viewshed_impact_example_detail.png">
<img src="r_viewshed_impact_example_detail.png"
width="591" height="469"
alt="Example of r.viewshed.impact - visibility impact map" border="0">
</a><br>
<i>Example of r.viewshed.impact - visibility impact map</i>
</div>

<h2>TODO</h2>
<ul>
  <li>Implement variable exposure source height.</li>
</ul>

<h2>KNOWN ISSUES</h2>
<ul>
  <li>Only areas with centroid within the computational region are processed.
  Areas with centroid outside the computational region are skipped.</li>
</ul>

<h2>REFERENCES</h2>
<ul>
<li>Cimburova, Z., Blumentrath, S., Barton, D., 2022. Making trees visible: a GIS method and tool for modelling visibilty in valuation of urban trees. Manuscript submitted for publication.
</li>
</ul>

<h2>SEE ALSO</h2>
<em>
<a href="r.viewshed.html">r.viewshed</a>,
<a href="r.viewshed.exposure.html">r.viewshed.exposure</a>,
<a href="r.viewshed.cva.html">r.viewshed.cva</a>
</em>

<h2>AUTHORS</h2>
Zofie Cimburova, <a href="https://www.nina.no">NINA</a><br>
Stefan Blumentrath, <a href="https://www.nina.no">NINA</a>
